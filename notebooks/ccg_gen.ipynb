{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for CCG Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexicon:\n",
    "    def __init__(self):\n",
    "        # Dictionary to store lexical entries, where the key is a word\n",
    "        # and the value is a list of categories (with optional semantics).\n",
    "        self.entries = {}\n",
    "\n",
    "\n",
    "    def add_entry(self, word, category, semantics=None):\n",
    "        # Add a lexical entry to the lexicon.\n",
    "        if word not in self.entries:\n",
    "            self.entries[word] = []\n",
    "        self.entries[word].append({'category': category, 'semantics': semantics})\n",
    "\n",
    "    def get_categories(self, word):\n",
    "        # Retrieve all categories for a given word.\n",
    "        return self.entries.get(word, [])\n",
    "\n",
    "    def __str__(self):\n",
    "        # Display all entries in the lexicon.\n",
    "        lexicon_str = \"Lexicon:\\n\"\n",
    "        for word, categories in self.entries.items():\n",
    "            lexicon_str += f\"{word}:\\n\"\n",
    "            for entry in categories:\n",
    "                semantics = entry['semantics'] if entry['semantics'] else 'None'\n",
    "                lexicon_str += f\"  - Category: {entry['category']}, Semantics: {semantics}\\n\"\n",
    "        return lexicon_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Lexicon\n",
    "lexicon = Lexicon()\n",
    "\n",
    "# Add entries\n",
    "lexicon.add_entry(\"John\", \"NP\", semantics=\"john\")\n",
    "lexicon.add_entry(\"Mary\", \"NP\", semantics=\"mary\")\n",
    "lexicon.add_entry(\"likes\", \"(S\\\\NP)/NP\", semantics=\"λx.λy.likes(y, x)\")\n",
    "lexicon.add_entry(\"runs\", \"S\\\\NP\", semantics=\"λx.runs(x)\")\n",
    "lexicon.add_entry(\"the\", \"NP/N\", semantics=\"λx.x\")\n",
    "lexicon.add_entry(\"dog\", \"N\", semantics=\"dog\")\n",
    "lexicon.add_entry(\"cat\", \"N\", semantics=\"cat\")\n",
    "\n",
    "# Handle ambiguous entries (e.g., \"saw\" as both a verb and noun)\n",
    "lexicon.add_entry(\"saw\", \"(S\\\\NP)/NP\", semantics=\"λx.λy.saw(y, x)\")\n",
    "lexicon.add_entry(\"saw\", \"N\", semantics=\"saw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories for 'likes':\n",
      "  - Category: (S\\NP)/NP, Semantics: λx.λy.likes(y, x)\n",
      "Lexicon:\n",
      "John:\n",
      "  - Category: NP, Semantics: john\n",
      "Mary:\n",
      "  - Category: NP, Semantics: mary\n",
      "likes:\n",
      "  - Category: (S\\NP)/NP, Semantics: λx.λy.likes(y, x)\n",
      "runs:\n",
      "  - Category: S\\NP, Semantics: λx.runs(x)\n",
      "the:\n",
      "  - Category: NP/N, Semantics: λx.x\n",
      "dog:\n",
      "  - Category: N, Semantics: dog\n",
      "cat:\n",
      "  - Category: N, Semantics: cat\n",
      "saw:\n",
      "  - Category: (S\\NP)/NP, Semantics: λx.λy.saw(y, x)\n",
      "  - Category: N, Semantics: saw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve categories for a specific word\n",
    "word = \"likes\"\n",
    "print(f\"Categories for '{word}':\")\n",
    "for entry in lexicon.get_categories(word):\n",
    "    print(f\"  - Category: {entry['category']}, Semantics: {entry['semantics']}\")\n",
    "\n",
    "# Print the entire lexicon\n",
    "print(lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating sentences without semantic constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class SentenceGenerator: \n",
    "    #A class is a blueprint for creating objects (instances), \n",
    "    # which can hold data and have functions (methods) associated with them.\n",
    "    def __init__(self, lexicon): \n",
    "        # Constructor method for the class: special method in Python automatically called when an \n",
    "        # object (an instance of the class) is created.\n",
    "        self.lexicon = lexicon \n",
    "        # This line stores the lexicon parameter passed to the constructor as an instance attribute.\n",
    "\n",
    "    def generate_sentence(self, target_category=\"S\"):\n",
    "        # Generate a sentence that matches the target category (default is 'S' for a sentence).\n",
    "        # Defines a method named generate_sentence: \n",
    "        # a member function of the SentenceGenerator class, \n",
    "        # meaning it operates on instances of that class.\n",
    "        sentence, remaining_category = self.build_sentence(target_category) \n",
    "        # This line calls the build_sentence method: result is expected to be a tuple.\n",
    "        \n",
    "        # If we couldn't completely match the category, return None\n",
    "        if remaining_category is None: #This part handles the outcome of the sentence generation.\n",
    "            return \" \".join(sentence)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def generate_multiple_sentences(self, target_category=\"S\", count=5):\n",
    "        # Generate multiple unique sentences that match the target category.\n",
    "        sentences = set() #This is a set that will hold the unique sentences generated.\n",
    "        attempts = 0 #This counter keeps track of the number of attempts made to generate a sentence.\n",
    "        max_attempts = count * 5  # Allow multiple attempts to find unique sentences\n",
    "        \n",
    "        # Ensures loop continues until desired number of unique sentences has been generated or \n",
    "        # max number of attempts is reached.\n",
    "        while len(sentences) < count and attempts < max_attempts:\n",
    "            attempts += 1\n",
    "            sentence = self.generate_sentence(target_category)\n",
    "            if sentence and sentence not in sentences:\n",
    "                sentences.add(sentence)\n",
    "        \n",
    "        return list(sentences)\n",
    "\n",
    "    def build_sentence(self, target_category, depth=0, max_depth=10):\n",
    "        # Recursively build a sentence by matching words to the target category.\n",
    "        if depth > max_depth: \n",
    "            #This block checks if the current recursion depth has exceeded the maximum allowed depth\n",
    "            print(f\"Exceeded max recursion depth: {depth} for target {target_category}\")\n",
    "            return [], target_category #safeguard to avoid an infinite recursion loop\n",
    "        \n",
    "        if target_category == \"S\":\n",
    "            # Decompose S into NP and S\\NP\n",
    "            print(\"Decomposing S into NP and S\\\\NP\")\n",
    "            # The method calls self.build_sentence recursively to generate a noun phrase (\"NP\"). \n",
    "            # The recursion depth is increased by 1 (depth + 1) to track the level of recursion.\n",
    "            # np_sentence will store the generated noun phrase.\n",
    "            # np_category will store the resulting category after attempting to build the NP.\n",
    "            np_sentence, np_category = self.build_sentence(\"NP\", depth + 1, max_depth)\n",
    "            # This checks if the np_category is None, indicating the NP was successfully generated \n",
    "            # (since build_sentence returns None when it successfully generates a category).\n",
    "            if np_category is None:  # NP found\n",
    "                print(f\"NP successfully resolved: {np_sentence}\")\n",
    "                # The method then tries to build the remaining part of the sentence, \n",
    "                # which is the verb phrase (S\\NP).\n",
    "                snp_sentence, snp_category = self.build_sentence(\"S\\\\NP\", depth + 1, max_depth)\n",
    "                if snp_category is None:  # S\\NP found\n",
    "                    print(f\"Successfully decomposed S: NP='{np_sentence}' and S\\\\NP='{snp_sentence}'\")\n",
    "                    # The method then returns a tuple consisting of:\n",
    "                    # The concatenated string of the noun phrase (np_sentence) and verb phrase \n",
    "                    # (snp_sentence), forming the complete sentence.\n",
    "                    # None, indicating that there are no remaining categories to expand\n",
    "                    return np_sentence + snp_sentence, None\n",
    "                else:\n",
    "                    print(f\"Failed to resolve S\\\\NP after matching NP='{np_sentence}'\")\n",
    "            else:\n",
    "                print(f\"Failed to resolve NP for S decomposition\")\n",
    "\n",
    "        # Shuffle lexicon keys for random selection\n",
    "        lexicon_keys = list(self.lexicon.entries.keys())\n",
    "        random.shuffle(lexicon_keys)\n",
    "\n",
    "        for word in lexicon_keys: # iterating through each word in the lexicon keys, \n",
    "            entries = self.lexicon.entries[word] #retrieving the associated entries\n",
    "            for entry in entries:\n",
    "                category = entry['category']\n",
    "                print(f\"Trying word '{word}' with category '{category}' to match '{target_category}'\")\n",
    "\n",
    "                # Direct match:\n",
    "                # if the category of the current word exactly matches the target_category, \n",
    "                # the word is directly returned as part of the sentence.\n",
    "                if self.normalize_category(category) == self.normalize_category(target_category):\n",
    "                    print(f\"Direct match found: '{word}' for category '{target_category}'\")\n",
    "                    return [word], None\n",
    "\n",
    "                # Forward application: (A/B) + B → A\n",
    "                if self.is_forward_function(category):\n",
    "                    left_category, right_category = map(self.normalize_category, self.split_category(category)) #the category is split \n",
    "                    if self.normalize_category(target_category) == left_category: #checks if the target_category matches the left_category\n",
    "                        print(f\"Attempting forward application: '{word}' as ({left_category}/{right_category})\")\n",
    "                        #it attempts forward application, meaning it tries to recursively generate the right_sentence for the right_category.\n",
    "                        right_sentence, remaining_category = self.build_sentence(right_category, depth + 1, max_depth)\n",
    "                        if remaining_category is None:\n",
    "                            print(f\"Forward application successful for '{word}'\")\n",
    "                            return [word] + right_sentence, None\n",
    "\n",
    "                # Backward application: B + (A\\B) → A\n",
    "                if self.is_backward_function(category):\n",
    "                    left_category, right_category = map(self.normalize_category, self.split_category(category))\n",
    "                    if self.normalize_category(target_category) == left_category:\n",
    "                        print(f\"Attempting backward application: '{word}' as ({left_category}\\\\{right_category})\")\n",
    "                        left_sentence, remaining_category = self.build_sentence(right_category, depth + 1, max_depth)\n",
    "                        if remaining_category is None:\n",
    "                            print(f\"Backward application successful for '{word}'\")\n",
    "                            return left_sentence + [word], None\n",
    "\n",
    "        # No match found, return failure case\n",
    "        print(f\"No match found for target '{target_category}' at depth {depth}\")\n",
    "        return [], target_category\n",
    "\n",
    "    def is_forward_function(self, category):\n",
    "        # Check if the category is a forward function (A/B).\n",
    "        return \"/\" in category\n",
    "\n",
    "    def is_backward_function(self, category):\n",
    "        # Check if the category is a backward function (A\\B).\n",
    "        return \"\\\\\" in category\n",
    "\n",
    "    def split_category(self, function_category):\n",
    "        # Split a function category (A/B or A\\B) into its components A and B.\n",
    "        if \"/\" in function_category:\n",
    "            return function_category.split(\"/\", 1)\n",
    "        elif \"\\\\\" in function_category:\n",
    "            return function_category.split(\"\\\\\", 1)\n",
    "        return None, None\n",
    "    \n",
    "    def normalize_category(self, category):\n",
    "        # Remove unnecessary parentheses from a category.\n",
    "        while category.startswith(\"(\") and category.endswith(\")\"):\n",
    "            category = category[1:-1]\n",
    "        return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposing S into NP and S\\NP\n",
      "Trying word 'saw' with category '(S\\NP)/NP' to match 'NP'\n",
      "Trying word 'saw' with category 'N' to match 'NP'\n",
      "Trying word 'dog' with category 'N' to match 'NP'\n",
      "Trying word 'cat' with category 'N' to match 'NP'\n",
      "Trying word 'Mary' with category 'NP' to match 'NP'\n",
      "Direct match found: 'Mary' for category 'NP'\n",
      "NP successfully resolved: ['Mary']\n",
      "Trying word 'cat' with category 'N' to match 'S\\NP'\n",
      "Trying word 'saw' with category '(S\\NP)/NP' to match 'S\\NP'\n",
      "Attempting forward application: 'saw' as (S\\NP/NP)\n",
      "Trying word 'Mary' with category 'NP' to match 'NP'\n",
      "Direct match found: 'Mary' for category 'NP'\n",
      "Forward application successful for 'saw'\n",
      "Successfully decomposed S: NP='['Mary']' and S\\NP='['saw', 'Mary']'\n",
      "Decomposing S into NP and S\\NP\n",
      "Trying word 'John' with category 'NP' to match 'NP'\n",
      "Direct match found: 'John' for category 'NP'\n",
      "NP successfully resolved: ['John']\n",
      "Trying word 'John' with category 'NP' to match 'S\\NP'\n",
      "Trying word 'the' with category 'NP/N' to match 'S\\NP'\n",
      "Trying word 'Mary' with category 'NP' to match 'S\\NP'\n",
      "Trying word 'saw' with category '(S\\NP)/NP' to match 'S\\NP'\n",
      "Attempting forward application: 'saw' as (S\\NP/NP)\n",
      "Trying word 'dog' with category 'N' to match 'NP'\n",
      "Trying word 'the' with category 'NP/N' to match 'NP'\n",
      "Attempting forward application: 'the' as (NP/N)\n",
      "Trying word 'likes' with category '(S\\NP)/NP' to match 'N'\n",
      "Trying word 'saw' with category '(S\\NP)/NP' to match 'N'\n",
      "Trying word 'saw' with category 'N' to match 'N'\n",
      "Direct match found: 'saw' for category 'N'\n",
      "Forward application successful for 'the'\n",
      "Forward application successful for 'saw'\n",
      "Successfully decomposed S: NP='['John']' and S\\NP='['saw', 'the', 'saw']'\n",
      "Decomposing S into NP and S\\NP\n",
      "Trying word 'Mary' with category 'NP' to match 'NP'\n",
      "Direct match found: 'Mary' for category 'NP'\n",
      "NP successfully resolved: ['Mary']\n",
      "Trying word 'cat' with category 'N' to match 'S\\NP'\n",
      "Trying word 'runs' with category 'S\\NP' to match 'S\\NP'\n",
      "Direct match found: 'runs' for category 'S\\NP'\n",
      "Successfully decomposed S: NP='['Mary']' and S\\NP='['runs']'\n",
      "Decomposing S into NP and S\\NP\n",
      "Trying word 'saw' with category '(S\\NP)/NP' to match 'NP'\n",
      "Trying word 'saw' with category 'N' to match 'NP'\n",
      "Trying word 'John' with category 'NP' to match 'NP'\n",
      "Direct match found: 'John' for category 'NP'\n",
      "NP successfully resolved: ['John']\n",
      "Trying word 'runs' with category 'S\\NP' to match 'S\\NP'\n",
      "Direct match found: 'runs' for category 'S\\NP'\n",
      "Successfully decomposed S: NP='['John']' and S\\NP='['runs']'\n",
      "Decomposing S into NP and S\\NP\n",
      "Trying word 'cat' with category 'N' to match 'NP'\n",
      "Trying word 'dog' with category 'N' to match 'NP'\n",
      "Trying word 'John' with category 'NP' to match 'NP'\n",
      "Direct match found: 'John' for category 'NP'\n",
      "NP successfully resolved: ['John']\n",
      "Trying word 'runs' with category 'S\\NP' to match 'S\\NP'\n",
      "Direct match found: 'runs' for category 'S\\NP'\n",
      "Successfully decomposed S: NP='['John']' and S\\NP='['runs']'\n",
      "Decomposing S into NP and S\\NP\n",
      "Trying word 'dog' with category 'N' to match 'NP'\n",
      "Trying word 'the' with category 'NP/N' to match 'NP'\n",
      "Attempting forward application: 'the' as (NP/N)\n",
      "Trying word 'saw' with category '(S\\NP)/NP' to match 'N'\n",
      "Trying word 'saw' with category 'N' to match 'N'\n",
      "Direct match found: 'saw' for category 'N'\n",
      "Forward application successful for 'the'\n",
      "NP successfully resolved: ['the', 'saw']\n",
      "Trying word 'Mary' with category 'NP' to match 'S\\NP'\n",
      "Trying word 'cat' with category 'N' to match 'S\\NP'\n",
      "Trying word 'saw' with category '(S\\NP)/NP' to match 'S\\NP'\n",
      "Attempting forward application: 'saw' as (S\\NP/NP)\n",
      "Trying word 'likes' with category '(S\\NP)/NP' to match 'NP'\n",
      "Trying word 'saw' with category '(S\\NP)/NP' to match 'NP'\n",
      "Trying word 'saw' with category 'N' to match 'NP'\n",
      "Trying word 'dog' with category 'N' to match 'NP'\n",
      "Trying word 'cat' with category 'N' to match 'NP'\n",
      "Trying word 'John' with category 'NP' to match 'NP'\n",
      "Direct match found: 'John' for category 'NP'\n",
      "Forward application successful for 'saw'\n",
      "Successfully decomposed S: NP='['the', 'saw']' and S\\NP='['saw', 'John']'\n",
      "Generated Sentences: ['Mary saw Mary', 'John saw the saw', 'John runs', 'the saw saw John', 'Mary runs']\n"
     ]
    }
   ],
   "source": [
    "# Create the generator given the lexicon\n",
    "generator = SentenceGenerator(lexicon)\n",
    "\n",
    "# Generate a single sentence\n",
    "#print(\"Generated Sentence:\", generator.generate_sentence(\"S\"))\n",
    "\n",
    "# Generate multiple unique sentences\n",
    "print(\"Generated Sentences:\", generator.generate_multiple_sentences(\"S\", count=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
