{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for CCG Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexicon:\n",
    "    def __init__(self):\n",
    "        # Dictionary to store lexical entries, where the key is a word\n",
    "        # and the value is a list of categories (with optional semantics).\n",
    "        self.entries = {}\n",
    "\n",
    "\n",
    "    def add_entry(self, word, category, semantics=None):\n",
    "        # Add a lexical entry to the lexicon.\n",
    "        if word not in self.entries:\n",
    "            self.entries[word] = []\n",
    "        self.entries[word].append({'category': category, 'semantics': semantics})\n",
    "\n",
    "    def get_categories(self, word):\n",
    "        # Retrieve all categories for a given word.\n",
    "        return self.entries.get(word, [])\n",
    "\n",
    "    def __str__(self):\n",
    "        # Display all entries in the lexicon.\n",
    "        lexicon_str = \"Lexicon:\\n\"\n",
    "        for word, categories in self.entries.items():\n",
    "            lexicon_str += f\"{word}:\\n\"\n",
    "            for entry in categories:\n",
    "                semantics = entry['semantics'] if entry['semantics'] else 'None'\n",
    "                lexicon_str += f\"  - Category: {entry['category']}, Semantics: {semantics}\\n\"\n",
    "        return lexicon_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Lexicon\n",
    "lexicon = Lexicon()\n",
    "\n",
    "# Add entries\n",
    "lexicon.add_entry(\"John\", \"NP\", semantics=\"john\")\n",
    "lexicon.add_entry(\"Mary\", \"NP\", semantics=\"mary\")\n",
    "lexicon.add_entry(\"likes\", \"(S\\\\NP)/NP\", semantics=\"λx.λy.likes(y, x)\")\n",
    "lexicon.add_entry(\"runs\", \"S\\\\NP\", semantics=\"λx.runs(x)\")\n",
    "lexicon.add_entry(\"the\", \"NP/N\", semantics=\"λx.x\")\n",
    "lexicon.add_entry(\"dog\", \"N\", semantics=\"dog\")\n",
    "lexicon.add_entry(\"cat\", \"N\", semantics=\"cat\")\n",
    "\n",
    "# Handle ambiguous entries (e.g., \"saw\" as both a verb and noun)\n",
    "lexicon.add_entry(\"saw\", \"(S\\\\NP)/NP\", semantics=\"λx.λy.saw(y, x)\")\n",
    "lexicon.add_entry(\"saw\", \"N\", semantics=\"saw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories for 'likes':\n",
      "  - Category: (S\\NP)/NP, Semantics: λx.λy.likes(y, x)\n",
      "Lexicon:\n",
      "John:\n",
      "  - Category: NP, Semantics: john\n",
      "Mary:\n",
      "  - Category: NP, Semantics: mary\n",
      "likes:\n",
      "  - Category: (S\\NP)/NP, Semantics: λx.λy.likes(y, x)\n",
      "runs:\n",
      "  - Category: S\\NP, Semantics: λx.runs(x)\n",
      "the:\n",
      "  - Category: NP/N, Semantics: λx.x\n",
      "dog:\n",
      "  - Category: N, Semantics: dog\n",
      "cat:\n",
      "  - Category: N, Semantics: cat\n",
      "saw:\n",
      "  - Category: (S\\NP)/NP, Semantics: λx.λy.saw(y, x)\n",
      "  - Category: N, Semantics: saw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve categories for a specific word\n",
    "word = \"likes\"\n",
    "print(f\"Categories for '{word}':\")\n",
    "for entry in lexicon.get_categories(word):\n",
    "    print(f\"  - Category: {entry['category']}, Semantics: {entry['semantics']}\")\n",
    "\n",
    "# Print the entire lexicon\n",
    "print(lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating sentences without semantic constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class SentenceGenerator: \n",
    "    #A class is a blueprint for creating objects (instances), \n",
    "    # which can hold data and have functions (methods) associated with them.\n",
    "    def __init__(self, lexicon): \n",
    "        # Constructor method for the class: special method in Python automatically called when an \n",
    "        # object (an instance of the class) is created.\n",
    "        self.lexicon = lexicon \n",
    "        # This line stores the lexicon parameter passed to the constructor as an instance attribute.\n",
    "\n",
    "    def generate_sentence(self, target_category=\"S\"):\n",
    "        # Generate a sentence that matches the target category (default is 'S' for a sentence).\n",
    "        # Defines a method named generate_sentence: \n",
    "        # a member function of the SentenceGenerator class, \n",
    "        # meaning it operates on instances of that class.\n",
    "        sentence, remaining_category = self.build_sentence(target_category) \n",
    "        # This line calls the build_sentence method: result is expected to be a tuple.\n",
    "        \n",
    "        # If we couldn't completely match the category, return None\n",
    "        if remaining_category is None: #This part handles the outcome of the sentence generation.\n",
    "            return \" \".join(sentence)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def generate_multiple_sentences(self, target_category=\"S\", count=5):\n",
    "        # Generate multiple unique sentences that match the target category.\n",
    "        sentences = set() #This is a set that will hold the unique sentences generated.\n",
    "        attempts = 0 #This counter keeps track of the number of attempts made to generate a sentence.\n",
    "        max_attempts = count * 5  # Allow multiple attempts to find unique sentences\n",
    "        \n",
    "        # Ensures loop continues until desired number of unique sentences has been generated or \n",
    "        # max number of attempts is reached.\n",
    "        while len(sentences) < count and attempts < max_attempts:\n",
    "            attempts += 1\n",
    "            sentence = self.generate_sentence(target_category)\n",
    "            if sentence and sentence not in sentences:\n",
    "                sentences.add(sentence)\n",
    "        \n",
    "        return list(sentences)\n",
    "\n",
    "    def build_sentence(self, target_category, depth=0, max_depth=10):\n",
    "        # Recursively build a sentence by matching words to the target category, with a tree.\n",
    "        if depth > max_depth:\n",
    "            print(f\"Exceeded max recursion depth: {depth} for target {target_category}\")\n",
    "            return [], None, None  # Include tree in return values\n",
    "\n",
    "        if target_category == \"S\":\n",
    "            # Decompose S into NP and S\\NP\n",
    "            print(\"Decomposing S into NP and S\\\\NP\")\n",
    "            np_sentence, np_category, np_tree = self.build_sentence(\"NP\", depth + 1, max_depth)\n",
    "            if np_category is None:  # NP found\n",
    "                print(f\"NP successfully resolved: {np_sentence}\")\n",
    "                snp_sentence, snp_category, snp_tree = self.build_sentence(\"S\\\\NP\", depth + 1, max_depth)\n",
    "                if snp_category is None:  # S\\NP found\n",
    "                    print(f\"Successfully decomposed S: NP='{np_sentence}' and S\\\\NP='{snp_sentence}'\")\n",
    "                    tree = {\n",
    "                        \"node\": \"S\",\n",
    "                        \"children\": [np_tree, snp_tree]\n",
    "                    }\n",
    "                    return np_sentence + snp_sentence, None, tree\n",
    "                else:\n",
    "                    print(f\"Failed to resolve S\\\\NP after matching NP='{np_sentence}'\")\n",
    "            else:\n",
    "                print(f\"Failed to resolve NP for S decomposition\")\n",
    "\n",
    "        lexicon_keys = list(self.lexicon.entries.keys())\n",
    "        random.shuffle(lexicon_keys)\n",
    "\n",
    "        for word in lexicon_keys:\n",
    "            entries = self.lexicon.entries[word]\n",
    "            for entry in entries:\n",
    "                category = entry['category']\n",
    "                print(f\"Trying word '{word}' with category '{category}' to match '{target_category}'\")\n",
    "\n",
    "                # Direct match:\n",
    "                if self.normalize_category(category) == self.normalize_category(target_category):\n",
    "                    print(f\"Direct match found: '{word}' for category '{target_category}'\")\n",
    "                    tree = {\"node\": target_category, \"children\": [word]}\n",
    "                    return [word], None, tree\n",
    "\n",
    "                # Forward application: (A/B) + B → A\n",
    "                if self.is_forward_function(category):\n",
    "                    left_category, right_category = map(self.normalize_category, self.split_category(category))\n",
    "                    if self.normalize_category(target_category) == left_category:\n",
    "                        print(f\"Attempting forward application: '{word}' as ({left_category}/{right_category})\")\n",
    "                        right_sentence, remaining_category, right_tree = self.build_sentence(right_category, depth + 1, max_depth)\n",
    "                        if remaining_category is None:\n",
    "                            print(f\"Forward application successful for '{word}'\")\n",
    "                            tree = {\n",
    "                                \"node\": left_category,\n",
    "                                \"children\": [{\"node\": f\"({left_category}/{right_category})\", \"children\": [word]}, right_tree]\n",
    "                            }\n",
    "                            return [word] + right_sentence, None, tree\n",
    "\n",
    "                # Backward application: B + (A\\B) → A\n",
    "                if self.is_backward_function(category):\n",
    "                    left_category, right_category = map(self.normalize_category, self.split_category(category))\n",
    "                    if self.normalize_category(target_category) == left_category:\n",
    "                        print(f\"Attempting backward application: '{word}' as ({left_category}\\\\{right_category})\")\n",
    "                        left_sentence, remaining_category, left_tree = self.build_sentence(right_category, depth + 1, max_depth)\n",
    "                        if remaining_category is None:\n",
    "                            print(f\"Backward application successful for '{word}'\")\n",
    "                            tree = {\n",
    "                                \"node\": left_category,\n",
    "                                \"children\": [left_tree, {\"node\": f\"({left_category}\\\\{right_category})\", \"children\": [word]}]\n",
    "                            }\n",
    "                            return left_sentence + [word], None, tree\n",
    "\n",
    "        print(f\"No match found for target '{target_category}' at depth {depth}\")\n",
    "        return [], target_category, None\n",
    "\n",
    "\n",
    "    def is_forward_function(self, category):\n",
    "        # Check if the category is a forward function (A/B).\n",
    "        return \"/\" in category\n",
    "\n",
    "    def is_backward_function(self, category):\n",
    "        # Check if the category is a backward function (A\\B).\n",
    "        return \"\\\\\" in category\n",
    "\n",
    "    def split_category(self, function_category):\n",
    "        # Split a function category (A/B or A\\B) into its components A and B.\n",
    "        if \"/\" in function_category:\n",
    "            return function_category.split(\"/\", 1)\n",
    "        elif \"\\\\\" in function_category:\n",
    "            return function_category.split(\"\\\\\", 1)\n",
    "        return None, None\n",
    "    \n",
    "    def normalize_category(self, category):\n",
    "        # Remove unnecessary parentheses from a category.\n",
    "        while category.startswith(\"(\") and category.endswith(\")\"):\n",
    "            category = category[1:-1]\n",
    "        return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anytree\n",
    "from anytree import Node, RenderTree\n",
    "\n",
    "# New code for visualizing the tree\n",
    "def build_visual_tree(tree, parent=None):\n",
    "    \"\"\"\n",
    "    Recursively convert the JSON-like tree into an anytree.Node tree.\n",
    "    \"\"\"\n",
    "    if isinstance(tree, dict):\n",
    "        node = Node(tree['node'], parent=parent)\n",
    "        for child in tree.get('children', []):\n",
    "            build_visual_tree(child, parent=node)\n",
    "        return node\n",
    "    elif isinstance(tree, str):  # Leaf node (word)\n",
    "        return Node(tree, parent=parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposing S into NP and S\\NP\n",
      "Trying word 'likes' with category '(S\\NP)/NP' to match 'NP'\n",
      "Trying word 'saw' with category '(S\\NP)/NP' to match 'NP'\n",
      "Trying word 'saw' with category 'N' to match 'NP'\n",
      "Trying word 'John' with category 'NP' to match 'NP'\n",
      "Direct match found: 'John' for category 'NP'\n",
      "NP successfully resolved: ['John']\n",
      "Trying word 'runs' with category 'S\\NP' to match 'S\\NP'\n",
      "Direct match found: 'runs' for category 'S\\NP'\n",
      "Successfully decomposed S: NP='['John']' and S\\NP='['runs']'\n",
      "Decomposing S into NP and S\\NP\n",
      "Trying word 'likes' with category '(S\\NP)/NP' to match 'NP'\n",
      "Trying word 'cat' with category 'N' to match 'NP'\n",
      "Trying word 'Mary' with category 'NP' to match 'NP'\n",
      "Direct match found: 'Mary' for category 'NP'\n",
      "NP successfully resolved: ['Mary']\n",
      "Trying word 'likes' with category '(S\\NP)/NP' to match 'S\\NP'\n",
      "Attempting forward application: 'likes' as (S\\NP/NP)\n",
      "Trying word 'runs' with category 'S\\NP' to match 'NP'\n",
      "Trying word 'the' with category 'NP/N' to match 'NP'\n",
      "Attempting forward application: 'the' as (NP/N)\n",
      "Trying word 'saw' with category '(S\\NP)/NP' to match 'N'\n",
      "Trying word 'saw' with category 'N' to match 'N'\n",
      "Direct match found: 'saw' for category 'N'\n",
      "Forward application successful for 'the'\n",
      "Forward application successful for 'likes'\n",
      "Successfully decomposed S: NP='['Mary']' and S\\NP='['likes', 'the', 'saw']'\n",
      "Decomposing S into NP and S\\NP\n",
      "Trying word 'Mary' with category 'NP' to match 'NP'\n",
      "Direct match found: 'Mary' for category 'NP'\n",
      "NP successfully resolved: ['Mary']\n",
      "Trying word 'likes' with category '(S\\NP)/NP' to match 'S\\NP'\n",
      "Attempting forward application: 'likes' as (S\\NP/NP)\n",
      "Trying word 'runs' with category 'S\\NP' to match 'NP'\n",
      "Trying word 'saw' with category '(S\\NP)/NP' to match 'NP'\n",
      "Trying word 'saw' with category 'N' to match 'NP'\n",
      "Trying word 'cat' with category 'N' to match 'NP'\n",
      "Trying word 'John' with category 'NP' to match 'NP'\n",
      "Direct match found: 'John' for category 'NP'\n",
      "Forward application successful for 'likes'\n",
      "Successfully decomposed S: NP='['Mary']' and S\\NP='['likes', 'John']'\n",
      "Decomposing S into NP and S\\NP\n",
      "Trying word 'saw' with category '(S\\NP)/NP' to match 'NP'\n",
      "Trying word 'saw' with category 'N' to match 'NP'\n",
      "Trying word 'Mary' with category 'NP' to match 'NP'\n",
      "Direct match found: 'Mary' for category 'NP'\n",
      "NP successfully resolved: ['Mary']\n",
      "Trying word 'saw' with category '(S\\NP)/NP' to match 'S\\NP'\n",
      "Attempting forward application: 'saw' as (S\\NP/NP)\n",
      "Trying word 'the' with category 'NP/N' to match 'NP'\n",
      "Attempting forward application: 'the' as (NP/N)\n",
      "Trying word 'John' with category 'NP' to match 'N'\n",
      "Trying word 'dog' with category 'N' to match 'N'\n",
      "Direct match found: 'dog' for category 'N'\n",
      "Forward application successful for 'the'\n",
      "Forward application successful for 'saw'\n",
      "Successfully decomposed S: NP='['Mary']' and S\\NP='['saw', 'the', 'dog']'\n",
      "Decomposing S into NP and S\\NP\n",
      "Trying word 'John' with category 'NP' to match 'NP'\n",
      "Direct match found: 'John' for category 'NP'\n",
      "NP successfully resolved: ['John']\n",
      "Trying word 'John' with category 'NP' to match 'S\\NP'\n",
      "Trying word 'dog' with category 'N' to match 'S\\NP'\n",
      "Trying word 'the' with category 'NP/N' to match 'S\\NP'\n",
      "Trying word 'likes' with category '(S\\NP)/NP' to match 'S\\NP'\n",
      "Attempting forward application: 'likes' as (S\\NP/NP)\n",
      "Trying word 'runs' with category 'S\\NP' to match 'NP'\n",
      "Trying word 'Mary' with category 'NP' to match 'NP'\n",
      "Direct match found: 'Mary' for category 'NP'\n",
      "Forward application successful for 'likes'\n",
      "Successfully decomposed S: NP='['John']' and S\\NP='['likes', 'Mary']'\n",
      "Generated Sentences and Trees:\n",
      "Sentence 1: John runs\n",
      "Tree Visualization:\n",
      "S\n",
      "├── NP\n",
      "│   └── John\n",
      "└── S\\NP\n",
      "    └── runs\n",
      "--------------------------------------------------\n",
      "Sentence 2: Mary likes the saw\n",
      "Tree Visualization:\n",
      "S\n",
      "├── NP\n",
      "│   └── Mary\n",
      "└── S\\NP\n",
      "    ├── (S\\NP/NP)\n",
      "    │   └── likes\n",
      "    └── NP\n",
      "        ├── (NP/N)\n",
      "        │   └── the\n",
      "        └── N\n",
      "            └── saw\n",
      "--------------------------------------------------\n",
      "Sentence 3: Mary likes John\n",
      "Tree Visualization:\n",
      "S\n",
      "├── NP\n",
      "│   └── Mary\n",
      "└── S\\NP\n",
      "    ├── (S\\NP/NP)\n",
      "    │   └── likes\n",
      "    └── NP\n",
      "        └── John\n",
      "--------------------------------------------------\n",
      "Sentence 4: Mary saw the dog\n",
      "Tree Visualization:\n",
      "S\n",
      "├── NP\n",
      "│   └── Mary\n",
      "└── S\\NP\n",
      "    ├── (S\\NP/NP)\n",
      "    │   └── saw\n",
      "    └── NP\n",
      "        ├── (NP/N)\n",
      "        │   └── the\n",
      "        └── N\n",
      "            └── dog\n",
      "--------------------------------------------------\n",
      "Sentence 5: John likes Mary\n",
      "Tree Visualization:\n",
      "S\n",
      "├── NP\n",
      "│   └── John\n",
      "└── S\\NP\n",
      "    ├── (S\\NP/NP)\n",
      "    │   └── likes\n",
      "    └── NP\n",
      "        └── Mary\n",
      "--------------------------------------------------\n",
      "\n",
      "Matrix saved to 'sentences_and_trees.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "generator = SentenceGenerator(lexicon)\n",
    "\n",
    "# Generate multiple sentences and store them in a matrix\n",
    "num_sentences = 5  # Adjust the number of sentences as needed\n",
    "matrix = []  # Initialize the matrix to store sentences and trees\n",
    "\n",
    "# Generate sentences and trees\n",
    "for _ in range(num_sentences):\n",
    "    sentence, _, tree = generator.build_sentence(\"S\")  # Generate sentence and its tree\n",
    "    matrix.append([\" \".join(sentence), tree])  # Append as a row in the matrix\n",
    "\n",
    "# Print the matrix with ASCII tree visualizations\n",
    "print(\"Generated Sentences and Trees:\")\n",
    "for i, (sentence, tree) in enumerate(matrix):\n",
    "    print(f\"Sentence {i + 1}: {sentence}\")\n",
    "    ascii_tree_root = build_visual_tree(tree)  # Convert tree to anytree format\n",
    "    print(\"Tree Visualization:\")\n",
    "    for pre, fill, node in RenderTree(ascii_tree_root):\n",
    "        print(f\"{pre}{node.name}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Save the matrix to a JSON file\n",
    "with open(\"sentences_and_trees.json\", \"w\") as f:\n",
    "    json.dump(matrix, f, indent=2)\n",
    "\n",
    "print(\"\\nMatrix saved to 'sentences_and_trees.json'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
